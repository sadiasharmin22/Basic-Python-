{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Nominal Categorical Features\n",
    "#You have a feature with with nominal classes that has no intrinsic ordering (e.g. apple, pear, banana).\n",
    "#Solution\n",
    "#One-hot encoding the feature using scikit-learn's LabelBinarizer:\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create feature\n",
    "feature =np.array ([['Texas'],['California'],['Texas'], ['Delaware'],['Florida'], ['Georgia'],['Alabama'],['Texas']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create one-hot encoder\n",
    "one_hot =LabelBinarizer()\n",
    "#One-hot encoder feature\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delaware', 'Florida', 'Georgia', 'Texas'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the classes_method to output the classes:\n",
    "#View feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Florida', 'Georgia',\n",
       "       'Alabama', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we want to reverse the one-hot encoding we can use inverse_transformation:\n",
    "#Reverse one-hot encoding\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alabama</th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Florida</th>\n",
       "      <th>Georgia</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alabama  California  Delaware  Florida  Georgia  Texas\n",
       "0        0           0         0        0        0      1\n",
       "1        0           1         0        0        0      0\n",
       "2        0           0         0        0        0      1\n",
       "3        0           0         1        0        0      0\n",
       "4        0           0         0        1        0      0\n",
       "5        0           0         0        0        1      0\n",
       "6        1           0         0        0        0      0\n",
       "7        0           0         0        0        0      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can even use pandas to one-hot encode the feature:\n",
    "#Import library\n",
    "import pandas as pd\n",
    "#Create dummy variables from feature\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One helpful ability of scikit-learn is to handle a situation where each observation lists multiple classes:\n",
    "#Create multiclass feature\n",
    "multiclass_feature =[( 'Texas','Florida'), \n",
    "                     ('California','Texas'), \n",
    "                     ('Delaware','Arizona'), \n",
    "                     ('Georgia','Alabama'),\n",
    "                     ('Texas','South Dacota'),\n",
    "                    ('Ohio','Louisiana')]\n",
    "#Create multiclass one-hot encoder\n",
    "one_hot_multiclass =MultiLabelBinarizer()\n",
    "#One-hot encode multiclass feature\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Arizona', 'California', 'Delaware', 'Florida',\n",
       "       'Georgia', 'Louisiana', 'Ohio', 'South Dacota', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Once again, we can see the classes with the classes_method:\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding Ordinal Categorical Features\n",
    "#Problem\n",
    "#You have an ordinal categorical feature (e.g. high, medium, low).\n",
    "#Solution\n",
    "#Use pandas DataFrame's replace method to transform string labels to numerical equivaments:\n",
    "#load library\n",
    "import pandas as pd\n",
    "#Create features\n",
    "dataframe =pd.DataFrame({'Score':['Low','Low','Medium','Medium','High'] })\n",
    "#Create_mapper\n",
    "scale_mapper={\"Low\":1, \"Medium\":2, \"High\":3}\n",
    "#Replace feature values with scale\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Diacussion \n",
    "####\n",
    "#####\n",
    "dataframe =pd.DataFrame({\"Score\":[\"Low\",\n",
    "                                  \"Low\", \n",
    "                                  \"Medium\",\n",
    "                                  \"Medium\", \n",
    "                                  \"High\", \n",
    "                                  \"Barely More Than Medium\"]})\n",
    "scale_mapper ={\"Low\":1,\n",
    "              \"Medium\":2,\n",
    "              \"Barely More Than Medium\":3,\n",
    "              \"High\":4}\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    3.0\n",
       "5    2.1\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "scale_mapper = {\"Low\":1, \"Medium\":2, \"Barely More Than Medium\":2.1,\n",
    "               \"High\":3}\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding Dictionaries of Features\n",
    "#Problem\n",
    "#You have a dictionary and wanted to convert it into a feature matrix.\n",
    "#Solution\n",
    "#Use DictVectorizer:\n",
    "#import library\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "#Create dictionary\n",
    "data_dict =[{\"Red\":2, \"Blue\":4},\n",
    "           {\"Red\":4, \"Blue\":3},\n",
    "           {\"Red\":1, \"Yellow\":2},\n",
    "           {\"Red\":2, \"Yellow\":2}]\n",
    "#Create dictionary vectorizer\n",
    "dictvectorizer =DictVectorizer(sparse=False)\n",
    "#Convert dictionary to feature matrix\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "#View feature matrix\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "###\n",
    "# We can get the names of each generated feature using the get_feature_names method:\n",
    "#get feature names\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "#view feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0\n",
       "3   0.0  2.0     2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#While not necessary, for the sake of illustration we can create a pandas DataFrame to view the output better:\n",
    "#Import library\n",
    "import pandas as pd\n",
    "#Create dataframe from features\n",
    "pd.DataFrame(features, columns =feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 2., 0.],\n",
       "       [3., 0., 4., 0.],\n",
       "       [5., 0., 1., 0.],\n",
       "       [0., 0., 2., 4.],\n",
       "       [0., 4., 3., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Discussion\n",
    "###dictvectorizer\n",
    "###\n",
    "###Create word counts dictionaries for four documents \n",
    "doc_1_word_count = {\"Red\":2, \"Blue\":4}\n",
    "doc_2_word_count = {\"Red\":4, \"Blue\":3}\n",
    "doc_3_word_count = {\"Red\":1, \"Blue\":5}\n",
    "doc_4_word_count = {\"Red\":2, \"Yellow\":4}\n",
    "doc_5_word_count = {\"Red\":3, \"Green\":4}\n",
    "\n",
    "##Create a list\n",
    "doc_word_counts = [ doc_1_word_count,\n",
    "                   doc_2_word_count, \n",
    "                   doc_3_word_count, \n",
    "                   doc_4_word_count, \n",
    "                   doc_5_word_count]\n",
    "\n",
    "##Conver list of word count dictionaries into a feature matrix\n",
    "dictvectorizer.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Imputing Missing Class Values\n",
    "#Problem\n",
    "#You have a categorical feature containing missing values that you want to replace with predicted values.\n",
    "#Solution\n",
    "## The ideal solution is to train a mechine learning classifier algorithm to predict the missing values, \n",
    "#commonly a k-nearest neighbour (KNN)classifier:\n",
    "#Load libraries\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create feature matrix with categorical feature\n",
    "X=np.array([[0, 2.10, 1.45],\n",
    "           [1, 1.18, 1.33],\n",
    "           [0, 1.22, 1.27],\n",
    "           [1,-0.21, -1.19]])\n",
    "\n",
    "#Create feature matrix with missing values in the categorical feature\n",
    "x_with_nan =np.array([[np.nan, 0.87, 1.31],\n",
    "                     [np.nan, -0.67, -0.22]])\n",
    "#Train KNN learner\n",
    "clf=KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "#Predict missing values' class\n",
    "imputed_values =trained_model.predict(x_with_nan[:, 1:])\n",
    "\n",
    "#Join column of predicted class with their other features\n",
    "X_with_imputed =np.hstack((imputed_values.reshape(-1,1), x_with_nan[:,1:]))\n",
    "\n",
    "#Join two feature matrices\n",
    "np.vstack((X_with_imputed,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An alternative solution is to fill in missing values with the feature's most frequent value:\n",
    "from sklearn.impute import SimpleImputer\n",
    "#Join the two feature matrices\n",
    "X_complete =np.vstack((x_with_nan, X))\n",
    "imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Imbalanced Classes\n",
    "#Problem\n",
    "#You have a target vector with highly uimbalanced classes\n",
    "#Solution\n",
    "#Collect more data. If it isn't possible, change the metrics used to evaluate your model. If that doesn't work, consider\n",
    "#using a model's build-in class weight parameters (if available),downsampling, or upsampling. \n",
    "\n",
    "#To demonstarte our solutions, we need to create some data with imbalanceed classes. \n",
    "#Fisher's Iris dataset contains three balanced classes of 50 observations, each indicating the species of flower \n",
    "#(Iris setosa, Iris virginica, Iris versicolor). To unbalance the dataset, we remove 40 of the 50 Iris setosa observations\n",
    "#and then merge the Iris virginica and Iris versicolor classes. The end result is a binary target vector indicating if an \n",
    "#observation is an Iris setosa flower or not. \n",
    "#The result is 10 observations of Iris setosa (class 0) and 100 observations of not Iris setosa (class1):\n",
    "\n",
    "#Load libraries\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load iris data\n",
    "iris=load_iris()\n",
    "\n",
    "#Create feature matrix\n",
    "feature=iris.data\n",
    "\n",
    "#Create target vector\n",
    "target =iris.target\n",
    "\n",
    "#Remove first 40 observations\n",
    "features =feature[40:,:]\n",
    "target =target[40:]\n",
    "\n",
    "#Create binary target vector indicating if class 0\n",
    "target =np.where((target == 0),0,1)\n",
    "\n",
    "#look at the imbalanced target vector\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1}, n_estimators=10, n_jobs=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Many algorithms in scikit-learn offer a parameter to weight classes during training to counteract the effect of\n",
    "#their imbalance. While we have not covered it yet, \n",
    "#RandomForestClassifier is a popular classification algorithm and includes a class_weight parameter.\n",
    "#You can pass an argument specifying the desited class weights explicitly:\n",
    "\n",
    "#create weights\n",
    "weights = {0:.9, 1:0.1}\n",
    "#Create random forest classifier with weights\n",
    "RandomForestClassifier(class_weight = weights)\n",
    "RandomForestClassifier(bootstrap = True, class_weight ={0:0.9, 1:0.1},\n",
    "                     criterion ='gini', max_depth =None, max_features ='auto',\n",
    "                     max_leaf_nodes =None, min_impurity_decrease=0.0,\n",
    "                     min_samples_split =2, min_weight_fraction_leaf=0.0,\n",
    "                     n_estimators =10, n_jobs=1,oob_score=False, random_state=None,\n",
    "                     verbose=0, warm_start =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=10, n_jobs=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Or you can pass balanced, which automatically creates weights inversely proportional to class frequencies:\n",
    "#Train a random forest with balanced class weights\n",
    "RandomForestClassifier(class_weight = \"balanced\")\n",
    "RandomForestClassifier(bootstrap = True, class_weight ='balanced',\n",
    "                     criterion ='gini', max_depth =None, max_features ='auto',\n",
    "                     max_leaf_nodes =None, min_impurity_decrease=0.0,\n",
    "                     min_samples_split =2, min_weight_fraction_leaf=0.0,\n",
    "                     n_estimators =10, n_jobs=1,oob_score=False, random_state=None,\n",
    "                     verbose=0, warm_start =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternatively, we can downsample the majority class or upsample the minority class.\n",
    "#In downsampling, we randomly sample without replacement from the majority class to create a new subset of observations\n",
    "#equal in size to the minority class.\n",
    "#For example, if the minority class has 10 observations, we will randomly select 10 observations from the majority class\n",
    "# and use those 20 observations as our data. \n",
    "#Indicies of each class observations\n",
    "i_class0 = np.where(target ==0)[0]\n",
    "i_class1= np.where(target ==1)[0]\n",
    "\n",
    "#Number of observations in each class\n",
    "n_class0 =len(i_class0)\n",
    "n_class1 =len(i_class1)\n",
    "\n",
    "#For every observation of class 0, randomly sample\n",
    "#from class 1 without replace\n",
    "i_class1_downsampled=np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "\n",
    "#Join together class 0's target vector with the\n",
    "#downsample class 1's targetr vector\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join together class 0's feature matrix with the \n",
    "#downsampled class 1's feature matrix\n",
    "np.vstack((features[i_class0,:], features [i_class1_downsampled,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our other option is to upsample the minority class. In upsampling, \n",
    "#for every observation in the majority class, we randomly select an observation from the minority class with replacement.\n",
    "#The end result is the same number of observations from the majority and minority classes. \n",
    "#Upsampling is implemented very similarly to down-sampling, just in reverse:\n",
    "\n",
    "#For every observation in class 1, randomly sample from class 0 witrh replacement\n",
    "i_class0_upsampled=np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "\n",
    "#Join together class 0's upsampled target wector with class 1's target vector \n",
    "np.concatenate((target[i_class0_upsampled], target [i_class1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 3. , 1.4, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join together calss 0's upsampled feature matrix with class 1's feature matrix\n",
    "np.vstack((features[i_class0_upsampled,:],features[i_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
